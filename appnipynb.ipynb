{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_ptQk-bcXwU",
        "outputId": "6889a3a0-289a-477f-c9df-894aa9e80d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#Installing required packages\n",
        "!pip install --quiet streamlit openai scikit-learn pandas joblib pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Download dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "columns = [f\"feature_{i}\" for i in range(57)] + [\"label\"]\n",
        "df = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Split and train model\n",
        "X = df.drop(\"label\", axis=1)\n",
        "y = df[\"label\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "print(classification_report(y_test, model.predict(X_test)))\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, \"spam_model.pkl\")\n",
        "print(\"‚úÖ Model trained and saved as spam_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJwEG4wwgjTd",
        "outputId": "4e0a5a60-187e-4443-de85-dcca388c01e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       531\n",
            "           1       0.98      0.92      0.95       390\n",
            "\n",
            "    accuracy                           0.96       921\n",
            "   macro avg       0.96      0.95      0.95       921\n",
            "weighted avg       0.96      0.96      0.96       921\n",
            "\n",
            "‚úÖ Model trained and saved as spam_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import re\n",
        "import joblib\n",
        "import openai\n",
        "\n",
        "#Setting OpenAI API key\n",
        "openai.api_key = \"sk-proj-................\"\n",
        "\n",
        "#Loading trained spam classifier model\n",
        "model = joblib.load(\"spam_model.pkl\")\n",
        "\n",
        "#Defining spammy keywords used in feature extraction\n",
        "spammy_keywords = [\n",
        "    \"free\", \"money\", \"win\", \"click\", \"remove\", \"order\", \"now\", \"guarantee\", \"urgent\", \"buy\",\n",
        "    \"offer\", \"credit\", \"cheap\", \"deal\", \"save\", \"cash\", \"discount\"\n",
        "]\n",
        "\n",
        "#Feature extraction using UCI Spambase style\n",
        "def extract_spambase_features(text: str):\n",
        "    text_lower = text.lower()\n",
        "    words = re.findall(r'\\b\\w+\\b', text_lower)\n",
        "    num_words = len(words) if words else 1\n",
        "    features = []\n",
        "\n",
        "    for word in spammy_keywords[:48]:\n",
        "        freq = text_lower.count(word) / num_words\n",
        "        features.append(freq)\n",
        "\n",
        "    for char in [';', '(', '[', '!', '$', '#']:\n",
        "        freq = text.count(char) / len(text) if len(text) > 0 else 0\n",
        "        features.append(freq)\n",
        "\n",
        "    capital_runs = re.findall(r'[A-Z]{2,}', text)\n",
        "    if capital_runs:\n",
        "        lengths = [len(run) for run in capital_runs]\n",
        "        avg = sum(lengths) / len(lengths)\n",
        "        max_run = max(lengths)\n",
        "        total = sum(lengths)\n",
        "    else:\n",
        "        avg = max_run = total = 0\n",
        "\n",
        "    features.extend([avg, max_run, total])\n",
        "\n",
        "    while len(features) < 57:\n",
        "        features.append(0)\n",
        "\n",
        "    return features\n",
        "\n",
        "#GPT-based classification\n",
        "def classify_email_gpt(email_text: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "You are a spam detection AI. Analyze the following email and say whether it is Spam or Not Spam.\n",
        "\n",
        "Respond exactly in this format:\n",
        "\n",
        "Spam or Not Spam\n",
        "Reason: <short reason>\n",
        "\n",
        "Email:\n",
        "\\\"\\\"\\\"\n",
        "{email_text}\n",
        "\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0,\n",
        "        )\n",
        "        return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"OpenAI API error: {e}\"\n",
        "\n",
        "#atreamlit UI\n",
        "st.set_page_config(page_title=\"SpamMorph\", layout=\"centered\")\n",
        "st.title(\"SpamMorph üîç GPT + ML Spam Classifier\")\n",
        "st.write(\"Enter email text to classify it as Spam or Not Spam using both GPT and ML models.\")\n",
        "\n",
        "email_text = st.text_area(\"üì® Paste your email text below:\", height=250)\n",
        "\n",
        "if email_text:\n",
        "    st.subheader(\"üìÑ Raw Email Text\")\n",
        "    st.write(email_text)\n",
        "\n",
        "    st.subheader(\"üß† GPT Verdict\")\n",
        "    gpt_result = classify_email_gpt(email_text)\n",
        "    st.success(gpt_result)\n",
        "\n",
        "    st.subheader(\"ü§ñ ML Model Verdict\")\n",
        "    features = extract_spambase_features(email_text)\n",
        "    features_df = pd.DataFrame([features], columns=[f\"feature_{i}\" for i in range(57)])\n",
        "    prediction = model.predict(features_df)[0]\n",
        "    pred_label = \"Spam üö´\" if prediction == 1 else \"Not Spam ‚úÖ\"\n",
        "    st.success(f\"ML Prediction: **{pred_label}**\")\n",
        "\n",
        "    confidence = model.predict_proba(features_df)[0][prediction]\n",
        "    st.write(f\"Prediction Confidence: **{confidence:.2%}**\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gTC59Dif1PQ",
        "outputId": "805a7624-95ca-44ea-aaed-3079f2f63e7d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-09 18:46:13.884 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.886 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.974 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-07-09 18:46:13.975 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.977 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.978 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.979 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.982 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.985 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.986 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.987 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.987 Session state does not function when running a script without `streamlit run`\n",
            "2025-07-09 18:46:13.988 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.990 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-09 18:46:13.991 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing and running Streamlit in background (via Colab tunneling)\n",
        "!pip install streamlit -q\n",
        "\n",
        "#Running Streamlit app in background\n",
        "!streamlit run app.py & npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqOQqwL_jLDh",
        "outputId": "952609bd-ab41-4850-8e4b-7daecb669cc5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.239.134.39:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0Kyour url is: https://crazy-kids-find.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(app_code)\n"
      ],
      "metadata": {
        "id": "Se1fP2yUd-6h"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}